## Задача:
Найти два предложения, ближайших по смыслу к заданному.
Например, задаем предложение №1, алгоритм возвращает 2 ближайших к нему по смыслу предложения (кроме его самого).

## Данные:
Новости нефтегазовой сферы по пути data/raw/text_raw.txt 

## Решение: 
Решение задачи отражено в notebook.ipynb

## Вывод:
В контексте задачи исследованы эмбеддинги трех моделей: 
- ai-forever/ruBert-base;
- DeepPavlov/rubert-base-cased;
- ai-forever/ruRoberta-large.

Установлено, что из исследованных моделей:
- DeepPavlov/rubert-base-cased лучше всех справляется с пониманием организационно-правовой информации;
- ai-forever/ruRoberta-large лучше всех справляет с пониманием технической информации, однако очень плохо понимает организационно-правовую информацию;
- ai-forever/ruBert-base немного хуже понимает техническую информацию, чем ai-forever/ruRoberta-large и организационно-правовую, чем DeepPavlov/rubert-base-cased, но фактически является самой сбалансированной, поэтому далее работа велась с ней. 

Евклидово расстояние, как способ определения векторного расстояния является наиболее оптимальным, другие способы определения расстояния показали себя хуже. 

Также в ходе работы из текстовых данных выделены именованные сущности: локации, персоны, организации, а также даты и нормализованный текст. 

Написан класс для работы с текстовыми данными, который: 
- принимает текстовые данные;
- формирует для них эмбеддинги, заданной моделью;
- выделяет из текстовых данных именованные сущности: имена, локации, компании, а также даты и нормализованный текст; 
- рассчитывает векторное расстояние заданным способом; 
- находит n-число схожих документов с учетом дополнительных фильтров. 

Работа с классом показала, что наличие дополнительных фильтров может улучшить поиск документов, делает его более гибким.